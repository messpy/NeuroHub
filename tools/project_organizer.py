#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Project Organizer - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“æ•´ç†ãƒ„ãƒ¼ãƒ«
- é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºãƒ»çµ±åˆ
- MCPã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ•´ç†
- ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆ
- DBãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆ
"""

import os
import json
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Any
from collections import defaultdict
import hashlib


class ProjectOrganizer:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•´ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, project_root: Path):
        self.project_root = Path(project_root)
        self.rules = self._load_organization_rules()
        
    def _load_organization_rules(self) -> Dict[str, Any]:
        """æ•´ç†ãƒ«ãƒ¼ãƒ«å®šç¾©"""
        return {
            "merge_directories": {
                "tests/": [
                    "test/",
                    "testing/",
                    "test_*/"
                ],
                "docs/": [
                    "documentation/",
                    "doc/",
                    "docs_*/"
                ],
                "_archive/old_tests/": [
                    "simple_*",
                    "debug_*",
                    "validate_*",
                    "fix_*",
                    "*_test_*"
                ]
            },
            "file_consolidation": {
                "services/db/database.db": [
                    "neurohub_llm.db",
                    "*.db",
                    "database/*"
                ],
                "docs/README.md": [
                    "README*.md",
                    "readme*.md"
                ],
                "docs/TESTING.md": [
                    "TEST_*.md",
                    "LINUX_TEST_*.md",
                    "*_TEST_*.md"
                ],
                "docs/SETUP.md": [
                    "LINUX_*.md",
                    "SETUP*.md",
                    "*_SETUP*.md"
                ]
            },
            "mcp_consolidation": {
                "services/mcp/": [
                    "mcp_*.py",
                    "*_mcp.py",
                    "simple_mcp_*"
                ]
            },
            "delete_patterns": [
                "*.tmp",
                "*.backup",
                "*.bak",
                "__pycache__/",
                "*.pyc",
                ".DS_Store",
                "*_backup*",
                "git_status_helper.py"  # ä¸€æ™‚ãƒ„ãƒ¼ãƒ«
            ]
        }

    def analyze_duplicates(self) -> Dict[str, List[str]]:
        """é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º"""
        file_hashes = defaultdict(list)
        duplicates = {}
        
        # ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
        for file_path in self.project_root.rglob("*"):
            if file_path.is_file() and not self._should_ignore(file_path):
                try:
                    with open(file_path, 'rb') as f:
                        file_hash = hashlib.md5(f.read()).hexdigest()
                        file_hashes[file_hash].append(str(file_path.relative_to(self.project_root)))
                except:
                    continue
        
        # é‡è¤‡æŠ½å‡º
        for file_hash, files in file_hashes.items():
            if len(files) > 1:
                duplicates[f"hash_{file_hash[:8]}"] = files
        
        return duplicates

    def analyze_similar_files(self) -> Dict[str, List[str]]:
        """é¡ä¼¼ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºï¼ˆåå‰ãƒ™ãƒ¼ã‚¹ï¼‰"""
        similar_groups = defaultdict(list)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        for file_path in self.project_root.rglob("*.py"):
            if file_path.is_file():
                name = file_path.stem
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
                base_patterns = [
                    name.replace("_test", "").replace("test_", ""),
                    name.replace("debug_", "").replace("_debug", ""),
                    name.replace("simple_", "").replace("_simple", ""),
                    name.replace("fix_", "").replace("_fix", ""),
                ]
                
                for pattern in base_patterns:
                    if pattern and len(pattern) > 3:
                        key = f"pattern_{pattern}"
                        similar_groups[key].append(str(file_path.relative_to(self.project_root)))
        
        # 2å€‹ä»¥ä¸Šã®ã‚°ãƒ«ãƒ¼ãƒ—ã®ã¿è¿”ã™
        return {k: v for k, v in similar_groups.items() if len(v) > 1}

    def _should_ignore(self, file_path: Path) -> bool:
        """ç„¡è¦–ã™ã¹ããƒ•ã‚¡ã‚¤ãƒ«åˆ¤å®š"""
        ignore_patterns = [
            ".git/", "__pycache__/", ".vscode/",
            "venv/", "venv_linux/", ".env",
            "node_modules/", ".pytest_cache/"
        ]
        
        path_str = str(file_path)
        return any(pattern in path_str for pattern in ignore_patterns)

    def create_organization_plan(self) -> Dict[str, Any]:
        """æ•´ç†è¨ˆç”»ä½œæˆ"""
        plan = {
            "timestamp": str(Path().cwd()),
            "actions": [],
            "summary": {}
        }
        
        # 1. é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
        duplicates = self.analyze_duplicates()
        for group, files in duplicates.items():
            if len(files) > 1:
                # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã™
                newest_file = max(files, key=lambda f: (self.project_root / f).stat().st_mtime)
                for file in files:
                    if file != newest_file:
                        plan["actions"].append({
                            "type": "delete_duplicate",
                            "file": file,
                            "keep": newest_file,
                            "reason": f"é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{group}ï¼‰"
                        })
        
        # 2. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªçµ±åˆ
        for target_dir, source_patterns in self.rules["merge_directories"].items():
            target_path = self.project_root / target_dir
            
            for pattern in source_patterns:
                for source_path in self.project_root.glob(pattern):
                    if source_path.is_dir() and source_path != target_path:
                        plan["actions"].append({
                            "type": "merge_directory",
                            "source": str(source_path.relative_to(self.project_root)),
                            "target": target_dir,
                            "reason": f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªçµ±åˆ: {pattern}"
                        })
        
        # 3. ãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆ
        for target_file, source_patterns in self.rules["file_consolidation"].items():
            target_path = self.project_root / target_file
            matching_files = []
            
            for pattern in source_patterns:
                matching_files.extend(self.project_root.glob(pattern))
            
            if len(matching_files) > 1:
                # çµ±åˆå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
                for source_path in matching_files:
                    if source_path.is_file() and source_path != target_path:
                        plan["actions"].append({
                            "type": "consolidate_file",
                            "source": str(source_path.relative_to(self.project_root)),
                            "target": target_file,
                            "reason": f"ãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆ: {pattern}"
                        })
        
        # 4. MCPçµ±åˆ
        mcp_files = []
        for pattern in self.rules["mcp_consolidation"]["services/mcp/"]:
            mcp_files.extend(self.project_root.glob(pattern))
        
        for mcp_file in mcp_files:
            if mcp_file.is_file() and "services/mcp/" not in str(mcp_file):
                plan["actions"].append({
                    "type": "move_to_mcp",
                    "source": str(mcp_file.relative_to(self.project_root)),
                    "target": f"services/mcp/{mcp_file.name}",
                    "reason": "MCPé–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆ"
                })
        
        # 5. å‰Šé™¤å¯¾è±¡
        for pattern in self.rules["delete_patterns"]:
            for file_path in self.project_root.glob(pattern):
                if file_path.is_file():
                    plan["actions"].append({
                        "type": "delete",
                        "file": str(file_path.relative_to(self.project_root)),
                        "reason": f"ä¸è¦ãƒ•ã‚¡ã‚¤ãƒ«: {pattern}"
                    })
        
        # ã‚µãƒãƒªãƒ¼ä½œæˆ
        action_types = defaultdict(int)
        for action in plan["actions"]:
            action_types[action["type"]] += 1
        
        plan["summary"] = {
            "total_actions": len(plan["actions"]),
            "by_type": dict(action_types),
            "affected_files": len(set(action.get("file", action.get("source", "")) for action in plan["actions"]))
        }
        
        return plan

    def execute_plan(self, plan: Dict[str, Any], dry_run: bool = True) -> Dict[str, Any]:
        """æ•´ç†è¨ˆç”»å®Ÿè¡Œ"""
        results = {
            "dry_run": dry_run,
            "executed": [],
            "failed": [],
            "skipped": []
        }
        
        for action in plan["actions"]:
            try:
                if action["type"] == "delete_duplicate":
                    file_path = self.project_root / action["file"]
                    if file_path.exists():
                        if not dry_run:
                            file_path.unlink()
                        results["executed"].append(action)
                    else:
                        results["skipped"].append({**action, "reason": "ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„"})
                
                elif action["type"] == "merge_directory":
                    source_path = self.project_root / action["source"]
                    target_path = self.project_root / action["target"]
                    
                    if source_path.exists():
                        if not dry_run:
                            target_path.mkdir(parents=True, exist_ok=True)
                            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
                            for item in source_path.rglob("*"):
                                if item.is_file():
                                    rel_path = item.relative_to(source_path)
                                    new_path = target_path / rel_path
                                    new_path.parent.mkdir(parents=True, exist_ok=True)
                                    shutil.move(str(item), str(new_path))
                            # ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤
                            if source_path.exists():
                                shutil.rmtree(source_path)
                        results["executed"].append(action)
                    else:
                        results["skipped"].append({**action, "reason": "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„"})
                
                elif action["type"] == "consolidate_file":
                    source_path = self.project_root / action["source"]
                    target_path = self.project_root / action["target"]
                    
                    if source_path.exists():
                        if not dry_run:
                            target_path.parent.mkdir(parents=True, exist_ok=True)
                            if target_path.exists():
                                # å†…å®¹ã‚’ãƒãƒ¼ã‚¸
                                with open(target_path, 'a', encoding='utf-8') as target_file:
                                    target_file.write(f"\n\n# --- Merged from {action['source']} ---\n\n")
                                    with open(source_path, 'r', encoding='utf-8') as source_file:
                                        target_file.write(source_file.read())
                            else:
                                shutil.move(str(source_path), str(target_path))
                        results["executed"].append(action)
                    else:
                        results["skipped"].append({**action, "reason": "ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„"})
                
                elif action["type"] == "move_to_mcp":
                    source_path = self.project_root / action["source"]
                    target_path = self.project_root / action["target"]
                    
                    if source_path.exists():
                        if not dry_run:
                            target_path.parent.mkdir(parents=True, exist_ok=True)
                            shutil.move(str(source_path), str(target_path))
                        results["executed"].append(action)
                    else:
                        results["skipped"].append({**action, "reason": "ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„"})
                
                elif action["type"] == "delete":
                    file_path = self.project_root / action["file"]
                    if file_path.exists():
                        if not dry_run:
                            if file_path.is_file():
                                file_path.unlink()
                            elif file_path.is_dir():
                                shutil.rmtree(file_path)
                        results["executed"].append(action)
                    else:
                        results["skipped"].append({**action, "reason": "ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„"})
                
            except Exception as e:
                results["failed"].append({**action, "error": str(e)})
        
        return results

    def generate_report(self, plan: Dict[str, Any]) -> str:
        """æ•´ç†ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = f"""# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•´ç†è¨ˆç”»

## æ¦‚è¦
- ç·ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°: {plan['summary']['total_actions']}
- å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {plan['summary']['affected_files']}

## ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç¨®åˆ¥
"""
        
        for action_type, count in plan['summary']['by_type'].items():
            report += f"- {action_type}: {count}ä»¶\n"
        
        report += "\n## è©³ç´°ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\n\n"
        
        for i, action in enumerate(plan['actions'][:20], 1):  # ä¸Šä½20ä»¶
            report += f"{i}. **{action['type']}**: "
            if 'source' in action:
                report += f"`{action['source']}` â†’ `{action.get('target', 'DELETE')}`"
            else:
                report += f"`{action.get('file', 'N/A')}`"
            report += f" ({action['reason']})\n"
        
        if len(plan['actions']) > 20:
            report += f"\n... ä»– {len(plan['actions']) - 20}ä»¶\n"
        
        return report


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Project Organizer - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•´ç†ãƒ„ãƒ¼ãƒ«")
    parser.add_argument("--analyze", action="store_true", help="åˆ†æã®ã¿å®Ÿè¡Œ")
    parser.add_argument("--execute", action="store_true", help="æ•´ç†å®Ÿè¡Œ")
    parser.add_argument("--dry-run", action="store_true", help="ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆå®Ÿéš›ã®å¤‰æ›´ãªã—ï¼‰")
    parser.add_argument("--report", type=str, help="ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«")
    
    args = parser.parse_args()
    
    project_root = Path(__file__).parent.parent
    organizer = ProjectOrganizer(project_root)
    
    if args.analyze or not args.execute:
        print("ğŸ” ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æä¸­...")
        plan = organizer.create_organization_plan()
        
        print(f"ğŸ“Š æ•´ç†è¨ˆç”»:")
        print(f"   ç·ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°: {plan['summary']['total_actions']}")
        print(f"   å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {plan['summary']['affected_files']}")
        
        for action_type, count in plan['summary']['by_type'].items():
            print(f"   {action_type}: {count}ä»¶")
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        if args.report:
            report = organizer.generate_report(plan)
            with open(args.report, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›: {args.report}")
        
        # è©³ç´°è¡¨ç¤ºï¼ˆä¸Šä½10ä»¶ï¼‰
        print("\nğŸ“‹ ä¸»è¦ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆä¸Šä½10ä»¶ï¼‰:")
        for i, action in enumerate(plan['actions'][:10], 1):
            print(f"   {i}. {action['type']}: ", end="")
            if 'source' in action:
                print(f"{action['source']} â†’ {action.get('target', 'DELETE')}")
            else:
                print(f"{action.get('file', 'N/A')}")
    
    if args.execute:
        print("\nğŸš€ æ•´ç†å®Ÿè¡Œä¸­...")
        plan = organizer.create_organization_plan()
        results = organizer.execute_plan(plan, dry_run=args.dry_run)
        
        print(f"âœ… å®Ÿè¡Œå®Œäº†:")
        print(f"   å®Ÿè¡Œ: {len(results['executed'])}ä»¶")
        print(f"   ã‚¹ã‚­ãƒƒãƒ—: {len(results['skipped'])}ä»¶")
        print(f"   å¤±æ•—: {len(results['failed'])}ä»¶")
        
        if results['failed']:
            print("\nâŒ å¤±æ•—é …ç›®:")
            for failed in results['failed'][:5]:
                print(f"   {failed.get('source', failed.get('file', 'N/A'))}: {failed['error']}")


if __name__ == "__main__":
    main()